{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T09:44:29.132800Z","iopub.status.busy":"2024-09-12T09:44:29.132392Z","iopub.status.idle":"2024-09-12T09:45:57.364794Z","shell.execute_reply":"2024-09-12T09:45:57.363818Z","shell.execute_reply.started":"2024-09-12T09:44:29.132759Z"},"trusted":true},"outputs":[],"source":["!pip install -q faiss-gpu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T09:45:57.366832Z","iopub.status.busy":"2024-09-12T09:45:57.366514Z","iopub.status.idle":"2024-09-12T09:47:26.183149Z","shell.execute_reply":"2024-09-12T09:47:26.182126Z","shell.execute_reply.started":"2024-09-12T09:45:57.366795Z"},"trusted":true},"outputs":[],"source":["!pip install -q translate\n","!pip install -q underthesea==1.3.5a3\n","!pip install -q underthesea[deep]\n","!pip install -q pyvi\n","!pip install -q langdetect\n","!pip install -q googletrans==3.1.0a0"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T09:34:07.558704Z","iopub.status.busy":"2024-09-12T09:34:07.558266Z","iopub.status.idle":"2024-09-12T09:35:19.465451Z","shell.execute_reply":"2024-09-12T09:35:19.464441Z","shell.execute_reply.started":"2024-09-12T09:34:07.558671Z"},"trusted":true},"outputs":[],"source":["lst_keyframes = []\n","for dirname, _, filenames in os.walk('/kaggle/input/'):\n","    for filename in filenames:\n","        if filename.endswith('.jpg'):\n","            lst_keyframes.append(os.path.join(dirname, filename))\n","lst_keyframes.sort()\n","\n","id2img_fps = dict()\n","for i, img_path in enumerate(lst_keyframes):\n","    id2img_fps[i] = img_path"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T09:47:42.922610Z","iopub.status.busy":"2024-09-12T09:47:42.922226Z","iopub.status.idle":"2024-09-12T09:47:59.663523Z","shell.execute_reply":"2024-09-12T09:47:59.662759Z","shell.execute_reply.started":"2024-09-12T09:47:42.922573Z"},"trusted":true},"outputs":[],"source":["from transformers import CLIPModel, CLIPImageProcessor, CLIPTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T09:42:21.253827Z","iopub.status.busy":"2024-09-12T09:42:21.253420Z","iopub.status.idle":"2024-09-12T09:42:21.261539Z","shell.execute_reply":"2024-09-12T09:42:21.260551Z","shell.execute_reply.started":"2024-09-12T09:42:21.253791Z"},"trusted":true},"outputs":[],"source":["model = [\n","    (\"openai/clip-vit-base-patch32\", 'clipB32'),\n","    (\"facebook/metaclip-b16-fullcc2.5b\", 'metaB16'),\n","    ('facebook/metaclip-l14-fullcc2.5b', 'metaL14'),\n","    ('facebook/metaclip-h14-fullcc2.5b', 'metaH14')\n","]\n","\n","model_name, bin_name = model[0]\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T09:42:22.872397Z","iopub.status.busy":"2024-09-12T09:42:22.872010Z","iopub.status.idle":"2024-09-12T09:42:53.503762Z","shell.execute_reply":"2024-09-12T09:42:53.502461Z","shell.execute_reply.started":"2024-09-12T09:42:22.872359Z"},"trusted":true},"outputs":[],"source":["model = CLIPModel.from_pretrained(model_name)\n","image_processor = CLIPImageProcessor.from_pretrained(model_name)\n","text_processor = CLIPTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:47:52.168587Z","iopub.status.idle":"2024-09-12T08:47:52.168961Z","shell.execute_reply":"2024-09-12T08:47:52.168800Z","shell.execute_reply.started":"2024-09-12T08:47:52.168781Z"},"trusted":true},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Class"]},{"cell_type":"markdown","metadata":{},"source":["## Translation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:47:52.178478Z","iopub.status.idle":"2024-09-12T08:47:52.178971Z","shell.execute_reply":"2024-09-12T08:47:52.178745Z","shell.execute_reply.started":"2024-09-12T08:47:52.178720Z"},"trusted":true},"outputs":[],"source":["class Translation():\n","    def __init__(self, from_lang='vi', to_lang='en', mode='google'):\n","        # The class Translation is a wrapper for the two translation libraries, googletrans and translate.\n","        self.__mode = mode\n","        self.__from_lang = from_lang\n","        self.__to_lang = to_lang\n","\n","        if mode in 'googletrans':\n","            self.translator = googletrans.Translator()\n","        elif mode in 'translate':\n","            self.translator = translate.Translator(from_lang=from_lang,to_lang=to_lang)\n","\n","    def preprocessing(self, text):\n","\n","        return text.lower()\n","\n","    def __call__(self, text):\n","\n","        text = self.preprocessing(text)\n","        return self.translator.translate(text) if self.__mode in 'translate' \\\n","                else self.translator.translate(text, dest=self.__to_lang).text"]},{"cell_type":"markdown","metadata":{},"source":["## Text preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:47:52.180575Z","iopub.status.idle":"2024-09-12T08:47:52.180912Z","shell.execute_reply":"2024-09-12T08:47:52.180760Z","shell.execute_reply.started":"2024-09-12T08:47:52.180743Z"},"trusted":true},"outputs":[],"source":["class Text_Preprocessing():\n","    def __init__(self, stopwords_path='./dict/vietnamese-stopwords-dash.txt'):\n","        with open(stopwords_path, 'rb') as f:\n","            lines = f.readlines()\n","        self.stop_words = [line.decode('utf8').replace('\\n','') for line in lines]\n","\n","    def find_substring(self, string1, string2):\n","\n","        match = SequenceMatcher(None, string1, string2, autojunk=False).find_longest_match(0, len(string1), 0, len(string2))\n","        return string1[match.a:match.a + match.size].strip()\n","\n","    def remove_stopwords(self, text):\n","\n","        text = ViTokenizer.tokenize(text)\n","        return \" \".join([w for w in text.split() if w not in self.stop_words])\n","\n","    def lowercasing(self, text):\n","        return text.lower()\n","\n","    def uppercasing(self, text):\n","        return text.upper()\n","\n","    def add_accents(self, text):\n","\n","        return ViUtils.add_accents(u\"{}\".format(text))\n","\n","    def remove_accents(self, text):\n","\n","        return ViUtils.remove_accents(u\"{}\".format(text))\n","\n","    def sentence_segment(self, text):\n","\n","        return underthesea.sent_tokenize(text)\n","\n","    def text_norm(self, text):\n","\n","        return underthesea.text_normalize(text)\n","\n","    def text_classify(self, text):\n","\n","        return underthesea.classify(text)\n","\n","    def sentiment_analysis(self, text):\n","\n","        return underthesea.sentiment(text)\n","\n","    def __call__(self, text):\n","\n","        text = self.lowercasing(text)\n","        text = self.remove_stopwords(text)\n","        # text = self.remove_accents(text)\n","        # text = self.add_accents(text)\n","        text = self.text_norm(text)\n","        categories = self.text_classify(text)\n","        return categories"]},{"cell_type":"markdown","metadata":{},"source":["## Myfaiss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:47:52.182300Z","iopub.status.idle":"2024-09-12T08:47:52.182668Z","shell.execute_reply":"2024-09-12T08:47:52.182485Z","shell.execute_reply.started":"2024-09-12T08:47:52.182462Z"},"trusted":true},"outputs":[],"source":["class Myfaiss:\n","    def __init__(self, bin_file : str,id2img_fps, device, model):\n","        self.index= self.load_bin_file(bin_file)\n","        self.id2img_fps= id2img_fps\n","        self.device= device\n","        self.model= model\n","\n","    def load_bin_file(self, bin_file: str):\n","        return faiss.read_index(bin_file)\n","\n","\n","    def show_images(self, image_paths):\n","        fig = plt.figure(figsize=(15, 10))\n","        columns = int(math.sqrt(len(image_paths)))\n","        rows = int(np.ceil(len(image_paths)/columns))\n","\n","        for i in range(1, columns*rows +1):\n","          img = plt.imread(image_paths[i - 1])\n","          ax = fig.add_subplot(rows, columns, i)\n","          ax.set_title(image_paths[i - 1].split('/')[-1].split('.')[0], fontsize=10)\n","#           ax.set_title('/'.join(image_paths[i - 1].split('/')[-3:]))\n","\n","          plt.imshow(img)\n","          plt.axis(\"off\")\n","\n","        plt.show()\n","\n","    def image_search(self, id_query, k, bin_file):\n","\n","        query_feats = self.index.reconstruct(id_query).reshape(1,-1)\n","\n","        scores, idx_image = self.index.search(query_feats, k=k)\n","        idx_image = idx_image.flatten()\n","\n","        infos_query = list(map(self.id2img_fps.get, list(idx_image)))\n","        image_paths = [info for info in infos_query]\n","\n","\n","        return scores, idx_image, infos_query, image_paths\n","\n","    def text_search(self, text, k):\n","        translater= Translation()\n","        if detect(text) == 'vi':\n","            text = translater(text)\n","\n","        ###### TEXT FEATURES EXACTING ######\n","        inputs = text_processor([text], return_tensors=\"pt\").to(device)\n","        text_features = model.get_text_features(**inputs).cpu().detach().numpy().astype(np.float32)        \n","        \n","        ###### SEARCHING #####\n","        scores, idx_image = self.index.search(text_features, k=k)\n","        idx_image = idx_image.flatten()\n","\n","        ###### GET INFOS KEYFRAMES_ID ######\n","        infos_query = list(map(self.id2img_fps.get, list(idx_image)))\n","        image_paths = [info for info in infos_query]\n","\n","        return scores, idx_image, infos_query, image_paths"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:47:52.186625Z","iopub.status.idle":"2024-09-12T08:47:52.187115Z","shell.execute_reply":"2024-09-12T08:47:52.186875Z","shell.execute_reply.started":"2024-09-12T08:47:52.186850Z"},"trusted":true},"outputs":[],"source":["bin_file=os.path.join(root_features, f'{bin_name}.bin')\n","faiss_test= Myfaiss(bin_file, id2img_fps, device, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:47:52.188353Z","iopub.status.idle":"2024-09-12T08:47:52.188723Z","shell.execute_reply":"2024-09-12T08:47:52.188560Z","shell.execute_reply.started":"2024-09-12T08:47:52.188521Z"},"trusted":true},"outputs":[],"source":["text = 'Một người đang trả lời phỏng vấn. Bức tường phía sau người này được treo rất nhiều hàm răng cá mập.'\n","\n","scores, idx_image, infos_query, image_paths = faiss_test.text_search(text, k=1)\n","faiss_test.show_images(image_paths)\n","print(scores)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5661683,"sourceId":9371169,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
